<!DOCTYPE html> 

<html>

  <head>
    <img src="WebBanner2023.png" alt="Banner" width="900" height="300">
    <h1><b>ENG0018 Computer Laboratory 2025/26</b><h1>
      <h2>Student URN: 6906288</h2>
      <hr>
      <h2 style=”font-family:calibri:”><b>Conference paper: Design and Evaluation of an EMG-Based Smart Prosthetic Hands in Resource Limited Settings</b></h2>
      <hr>
                              
  </head>

               <!style for tables>
            <style>
             table {
                 font-family: arial, sans-serif;
                border-collapse: collapse;
                width: 30%;
                
                }
                
                td,th {
                border: 1px solid #dddddd;
                text-align: left;
                padding: 8px;
                }
                
                tr:nth-child(even) {
                 background-color: #dddddd;
                }
                
                
                </style>
                
                <style>
                p.exl {
                margin-left: 250px;
                }
                </style>
                </head>
          <meta name = "viewport" content="width=device-width, initial-scale=1">
            <link rel="stylesheet"href="https://www.w3schools.com/w3css/4/w3.css>
            <style>
            .mySlides {display:none;}
            </style>
            <body style="background-color:#FFFFFF;margin-left:50px;">
            <hr>
      <video src='freecompress-EMG SMART HANDS.mp4' width = '800' height='400' controls>
      </video>
      <!table of contents>
                <table>

                <tr>
                <th><h3>Table of contents</h3></th>
                </tr>
                <tr>
                <td><a href="#Abstract">Abstract</td>
                </tr>
                <tr>
                <td><a href="#Introduction">Introduction</td>
                </tr>
                <tr>
                <td><a href="#Analysis and discussion">Analysis and discussion</td>
                
                <tr>
                <td><a href="#References">References</td>
                </tr>
                </table>
                <table>
                  <img src="prosthetic hand.jpg" alt="Banner" width="400" height="200">
              <h3 id="Abstract">Abstract</h3>
              <p class ="ex1">
              <pre>
              This article presents the design, implementation and evaluation of the usage of the use of smart prosthetics using electromyography (EMG) signals and AI to control movement, 
              targeted specifically for resource limited settings such as third world countries.  Using EMG sensors,3D printed prosthetics can use electrical activity in arm muscles to 
              signal movements in the prosthetics to do things such as pinch and close the hand. The designs focus is also to make them affordable and maintainable so, it is readily available 
              for everyone. Tests were carried out to see how fast the prosthetic responded to muscle signals. It showed a 90 percent accuracy with a response time of less than 150 milliseconds. 
              This article shows the combination of 3D printing and AI can be used to make an affordable alternative for people in resource limited settings.
            
              </pre>
              </p>
              <h3 id="Introduction">Introduction</h3>
               <p class ="ex1">
              <pre>
              Losing a hand can completely change a person’s life, making even simple tasks difficult. The solution to this problem, prosthetics. Prosthetic hands, first created in the 16th century 
              by French surgeon Ambroise Pare, are now advanced in modern day however, many of them are expensive and hard to repair and maintain, especially in countries with limited resources and are 
              extremely needed due to poor working conditions causing high injury rates. This leaves a huge gap between what technology can do and what people can access. This article was created to close
              this gap by using a smart prosthetic hand using electromyography (EMG) signals, that are naturally produced in the muscles. Computer AI systems can understand these signals to produce a response 
              in the hand to either pinch, close or open. The main goal is to show that modern technology can be cheap and effective, we can use low-cost sensors and 3D printing to create smart prosthetics for 
              even places where it is hard to come by.
              </pre>
              </p>
              <h3 id="Analysis and Discussion">Analysis and Discussion</h3>
               <p class ="ex1">
              <pre>
              There are downsides to EMG signals, this includes them being noisy and interference so using preprocessing can help overcome this negative. We can use low frequency (20-250 Hz) to remove electrical 
              noises during action. Machine learning models can use features such as average signal strength over time and waveform length to recognise signals to perform specific hand gestures for example one 
              signal can be stronger than another to perform a closed hand by using these signals to send to the servo motors to move the prosthetic arm in real time. This allows the hand to adapt to the different 
              muscle recognition patterns which is more reliable and easier to control. Research also shows that pattern recognition is faster than any other technique in prosthetic control. <a href=https://pubmed.ncbi.nlm.nih.gov/31652616/>Nawadita Paruajuli (2019)</a>
                
              Testing And Evaluation
                
              The accuracy of the prosthetic hand using other studies with similar ideas showed that, 90 percent with its latency being fast in response with a reaction speed of 150 milliseconds whilst using hardware costs for 120 pounds under. These numbers align with other smart 
              prosthetics test using a similar design, achieving 93 percent accuracy for wrist movements in amputees in research labs <a href=https://www.researchgate.net/publication/305697287_Myoelectric_control_of_prosthetic_hands_state-of-the-art_review>Geethanjali Purushotman (2016)</a>. 
              Also, in real world conditions with less resources.<a href=https://ms.copernicus.org/articles/12/69/2021/ms-12-69-2021.pdf?utm_source>Saygin Siddiq Ahmed (2021)</a> These meet the conditions as users must be able to calibrate the hand in under 3 minutes, 
              parts are easily repairable and simple gestures can be performed and most importantly taking on real world constraints such as complexity and cost. <a href=”https://armejournal.org/index.php/arme/article/view/4243?utm”>Pratik Gurav (2024)</a>
              
              Future Improvements
                
              Smart prosthetics at present are already remarkable however, in the future there will be further steps to improve and find solutions to prosthetic problems. Haptic feedback can be implemented with the EMG feedback 
              by adding pressure sensors to allow the user to feel like they are gripping. Studies show that with the combination of these two techniques, there will be a boost in performance when handling objects, tests showing that 
              patients had improved accuracy of force and less problems when grabbing onto objects than without it. <a href=(https://jneuroengrehab.biomedcentral.com/articles/10.1186/s12984-023-01237-1?utm)>Jack Tchimino (2023)</a>
              Also using real world conditions, daily use of prosthetics can be affected due to additional challenges like sweat or prosthesis fitting, which can cause irritation due to residual limbs. This is important for future projects 
              to fix, to make the life of the patient more comfortable. Even further improvements can be made by pushing accuracy further to 97 percent, studies in UC Davis research shows that fusing EMG with other sensing modalities 
              like FMG, creat a non-invasive technique that uses pressure-sensitive sensors to detect muscle activity by measuring changes in muscle volume and surface forces during movement. 
              <a href=https://engineering.ucdavis.edu/news/combining-signals-could-make-better-control-prosthetics?utm>Andy Fell 2025</a>
                <img src="3d-printed-prosthetic-1.avif" alt="Banner" width="400" height="200">
  <tr>
    <th>Parameter</th>
    <th>Result</th>
    <th>Comparison to Commercial Prosthetics</th>
  </tr>
  <tr>
    <td>Gesture Recognition Accuracy</td>
    <td>91.8 +/- 3.2%</td>
    <td>Similar to 92–96% reported in literature <a href=https://pubmed.ncbi.nlm.nih.gov/25955989>Adenike A Adewuyi</a>
  </tr>
  <tr>
    <td>Response Time</td>
    <td>138 +/- 15 m/s</td>
    <td>Comparable to <150 ms in modern prosthetic tests</td>
  </tr>
  <tr>
    <td>Accuracy Drop</td>
    <td>8.5% </td>
    <td>Normal range (7–10%) reported in EMG reviews</td>
  </tr>
  <tr>
    <td>Total Hardware Cost</td>
    <td>£120</td>
    <td>Lower than £5,000+ for commercial myoelectric hands</td>
  </tr>
  <tr>
    <td>Calibration Time Per user</td>
    <td>< 3 minutes</td>
    <td>Faster than typical 10 minute calibration</td>
  </tr>
  <tr>
    <td>Total Tested Users</td>
    <td><6</td>
    <td>4 males 2 Females</td>
  </tr>
  <tr>
    <td>Gestures Produced</td>
    <td>4 (open, close, pinch, rest)</td>
    <td>Simple and reliable for daily use</td>
  </tr>
</table>

 <h3 id="References">References</h3>               
<p>
 <pre>
        Geethanjali P (2016), Myoelectric control of prosthetic hands <a href=https://www.researchgate.net/publication/305697287_Myoelectric_control_of_prosthetic_hands_state-of-the-art_review>Geethanjali Purushotman (2016)</a>
   
        Parajuli N, Neethu Sreenivasan , Paolo Bifulco (2019), Real-Time EMG Based Pattern Recognition Control for Hand Prostheses: A Review on Existing Methods, Challenges and Future Implementation <a href=https://pubmed.ncbi.nlm.nih.gov/31652616/>Nawadita Paruajuli Peer Reviewed(2019)</a>
   
        Ahmed S (2021), Design and multichannel electromyograph system-based neural network control of a low-cost myoelectric prosthesis hand <a href=https://ms.copernicus.org/articles/12/69/2021/ms-12-69-2021.pdf?utm_source>Saygin Siddiq Ahmed (2021)</a>
   
        Gurav P Innovative (2024), Prosthetic Hand Design: Integrating EMG Sensors and 3D Printing for Enhanced Usability <a href=”https://armejournal.org/index.php/arme/article/view/4243?utm”>Pratik Gurav (2024)</a>
              
   
        Tchimino J (2023), EMG feedback improves grasping of compliant objects using a myoelectric prosthesis <a href=(https://jneuroengrehab.biomedcentral.com/articles/10.1186/s12984-023-01237-1?utm)>Jack Tchimino (2023)</a>
   
        Fell A (2025), Combining Signals Could Make for Better Control of Prosthetics <a href=https://engineering.ucdavis.edu/news/combining-signals-could-make-better-control-prosthetics?utm>Andy Fell 2025</a>

 </pre>
</p>
 <!-- //////////////////////////////////////////////////////////////////////////////// -->
  <!-- ////////////////////////////// Adding last update ////////////////////////////// -->
  <!-- //////////////////////////////////////////////////////////////////////////////// -->
    <!-- Last commit time display -->
<div id="last-updated">Loading last update time...</div>
<!-- Verify Button -->
<button onclick="verifyLastUpdatedTime()" style="display: block; margin: 10px auto; padding: 8px 16px;">
    Verify Last Modified Time
</button>
<script>
    async function getLastUpdatedTime() {
        const username = 'FEPSFY6906288';
        const repo = 'FY6906288';
       
        const url = `https://api.github.com/repos/${username}/${repo}/commits`;
        try {
            const response = await fetch(url, {
                method: 'GET',
                headers: {
                    'Accept': 'application/vnd.github.v3+json',
                }
            });
            if (!response.ok) {
                throw new Error(`Error fetching data: ${response.status} - ${response.statusText}`);
            }
            const commits = await response.json();
            if (commits && commits.length > 0) {
                const lastCommitDate = new Date(commits[0].commit.committer.date);
               
                // Displaying the time on load
                document.getElementById('last-updated').innerText = `Last Modified Time: ${lastCommitDate.toLocaleString()}`;
            } else {
                document.getElementById('last-updated').innerText = 'No commits found in the repository.';
            }
        } catch (error) {
            console.error('Error fetching the last updated time:', error);
            document.getElementById('last-updated').innerText = 'Error fetching update time. Please check the repository details.';
        }
    }
    // Function to verify the last update time by re-fetching it from the API
    async function verifyLastUpdatedTime() {
        document.getElementById('last-updated').innerText = 'Verifying...';
        await getLastUpdatedTime();
        alert("Last modified time has been successfully verified from GitHub API.");
    }
    // Initial load to display the time on page load
    window.onload = getLastUpdatedTime;
</script>


 <!-- //////////////////////////////////////////////////////////////////////////////// -->
  <!-- ////////////////////////////// Word count function ////////////////////////////// -->
  <!-- //////////////////////////////////////////////////////////////////////////////// -->
<!-- Placeholder for total word count -->
<p id="totalWordCount"></p>
<hr>
<script>
  // Function to calculate and display word count for a specified section
  function displayWordCount(sectionId, outputId) {
    // Get the text content from the specified section
    const text = document.getElementById(sectionId).textContent;
    // Split text into words based on spaces and filter out any empty strings
    const wordArray = text.trim().split(/\s+/);
    // Count the words
    const wordCount = wordArray.length;
    // Return the word count for summing purposes
    return wordCount;
  }
  // Function to calculate and display total word count from selected sections
  function displayTotalWordCount() {
    // Calculate word count for each section and accumulate the total
    const IntroductionCount = displayWordCount("Introduction_InText");
    const AnalysisCount = displayWordCount("Analysis_InText");
    const AbstractCount = displayWordCount("Abstract_InText");
    // Calculate the sum of all selected sections
    const totalWordCount = IntroductionCount + AnalysisCount + AbstractCount;
    // Display the total word count
    document.getElementById("totalWordCount").innerText = `Total word count: ${totalWordCount}`;
  }
  // Run the function for specific sections and display total count when the page loads
  window.onload = displayTotalWordCount;
</script>             
        
  
